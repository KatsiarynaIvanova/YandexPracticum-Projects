{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8d89cc",
   "metadata": {},
   "source": [
    "# Определение токсичности комментариев "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5551617d",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "**Цель:**\n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.72. \n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.\n",
    "\n",
    "* text - текст комментария;\n",
    "* toxic - целевой признак (1-комментарий токсичен, 0-нетоксичен)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbcca82",
   "metadata": {},
   "source": [
    "# Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcca8802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e434ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/daivanov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/daivanov/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet') \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3835b045",
   "metadata": {},
   "source": [
    "# Изучение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8eab35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# чтение данных\n",
    "data = pd.read_csv('toxic_comments.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac6233b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff08fd4",
   "metadata": {},
   "source": [
    "Всего 159571 размещенный коментарий. Пропусков в данных нет. Тип данных клонок соответствует их содержанию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42225f26",
   "metadata": {},
   "source": [
    "Посмотрим соотношение положительных и токсичных коментариев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a3ffba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.841344371679229"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = data['toxic'].value_counts()[0] / data['toxic'].value_counts()[1]\n",
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f81de",
   "metadata": {},
   "source": [
    "Количество положительных коментариев почти в 9 раз больше, чем отрицательных. Классы несбалансированы.\n",
    "Для балансировки классов можно использовать:\n",
    "* настройки модели, изменение весов\n",
    "* увеличение выборки\n",
    "* уменьшение выборки\n",
    "\n",
    "Что бы не потерять данные проверим как изменится значение метрики, если увеличить выборку и если изменить вес класса в параметрах модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e379c955",
   "metadata": {},
   "source": [
    "# Подготовка текста к векторизации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40d051a",
   "metadata": {},
   "source": [
    "Напишем функции, которая на вход будет принимать текст, а возвращать лемматизированный и очищенный с помощью регулярных выражений текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e56445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишем функцию позволяющею подготовить текст для вектотризации\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def data_preparation(text):\n",
    "    \n",
    "    \"используем регулярные выражения для очистки текста\"\n",
    "        \n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    \n",
    "    text_lemm = [lemmatizer.lemmatize(word) for word in text]\n",
    "    \n",
    "    clean_text = \" \".join(text_lemm)\n",
    "       \n",
    "    return clean_text\n",
    "\n",
    "data['clean_text'] = data['text'].apply(data_preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a9b5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestion improvement wondered sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic  \\\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1           1  D'aww! He matches this background colour I'm s...      0   \n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          clean_text  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  aww match background colour seemingly stuck th...  \n",
       "2  hey man really trying edit war guy constantly ...  \n",
       "3  make real suggestion improvement wondered sect...  \n",
       "4                      sir hero chance remember page  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d6757",
   "metadata": {},
   "source": [
    "Теперь в нашей таблице появилась колонка `clean_text` с обработанным текстом."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6effdac",
   "metadata": {},
   "source": [
    "# Разбиение на тестовую и обучающую выборку"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965c09f",
   "metadata": {},
   "source": [
    "Разобьем данные на тестовую и обучающую выборку в соотношении 30:70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1819e556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111504,)\n",
      "(47788,)\n"
     ]
    }
   ],
   "source": [
    "target = data['toxic']\n",
    "features = data['clean_text']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features,\n",
    "                                                                            target,\n",
    "                                                                           test_size = 0.3,\n",
    "                                                                           random_state=12345)\n",
    "print(features_train.shape, features_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c197721",
   "metadata": {},
   "source": [
    "## Векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a0a12",
   "metadata": {},
   "source": [
    "### Мешок слов (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "813dd865",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "# векторизация исходной выборки\n",
    "features_train_bow = count_vect.fit_transform(features_train)\n",
    "features_test_bow = count_vect.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db17c6f",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b6491d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer()\n",
    "# векторизация исходной выборки\n",
    "features_train_idf = count_tf_idf.fit_transform(features_train)\n",
    "features_test_idf = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb7ab47",
   "metadata": {},
   "source": [
    "# Несбалансированность классов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a064fc0",
   "metadata": {},
   "source": [
    "Так как в дальнейшем при обучении моделей будем использовать кросс-валидацию, то использование upsampled/downsampled данных будет не корректно. В случае upsampling получается так, что в треин и в валидацию (внутри кросс-валидации) попадают одни и те же объекты. При обучении будем использовать class_weight='balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6b74d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([('vect', CountVectorizer()),\n",
    " ('tfidf', TfidfTransformer()),\n",
    " ('model', LogisticRegression(random_state=12345, class_weight='balanced'))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "877cec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daivanov/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/daivanov/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/daivanov/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/daivanov/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7482022499935457\n"
     ]
    }
   ],
   "source": [
    "# модель логистической регрессии с параметром class_weight='balanced' \n",
    "cross_val = cross_val_score(pipe_lr, \n",
    "                            features_train, \n",
    "                            target_train, \n",
    "                            scoring='f1', cv=5, n_jobs=-1).mean()\n",
    "\n",
    "print(cross_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c2d815",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddcc25b",
   "metadata": {},
   "source": [
    "* Значение метрики достигает **0.75** при обучении модели.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6fadd5",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416436f4",
   "metadata": {},
   "source": [
    "Обучем следующие модели:\n",
    "* LogisticRegression\n",
    "* DecisionTreeClassifier\n",
    "* GradientBoostingClassifier\n",
    "* RandomForestClassifie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de057427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# модели\n",
    "clf1 = Pipeline([('vect', CountVectorizer()),\n",
    " ('tfidf', TfidfTransformer()),\n",
    " ('model_clf1', RandomForestClassifier(random_state=12345))])\n",
    "\n",
    "clf2 = Pipeline([('vect', CountVectorizer()),\n",
    " ('tfidf', TfidfTransformer()),\n",
    " ('model_clf2', LogisticRegression(random_state=42))])\n",
    "\n",
    "clf3 = Pipeline([('vect', CountVectorizer()),\n",
    " ('tfidf', TfidfTransformer()),\n",
    " ('model_clf3', DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "\n",
    "\n",
    "clf4 = Pipeline([('vect', CountVectorizer()),\n",
    " ('tfidf', TfidfTransformer()),\n",
    " ('model_clf4', GradientBoostingClassifier(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbd150a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для каждой модели параметры для подбора\n",
    "param1 = {'model_clf1__n_estimators': range (10, 100),\n",
    "         'model_clf1__max_depth': range (1,80)\n",
    "         }\n",
    "\n",
    "param2 = {'model_clf2__solver': ['liblinear', 'sag','saga','newton-cg']}\n",
    "\n",
    "param3 = {'model_clf3__max_depth': range (1,80),\n",
    "         'model_clf3__min_samples_split': range(2,8),\n",
    "         }\n",
    "\n",
    "\n",
    "param4 = {'model_clf4__n_estimators' : range(10,100),\n",
    "         'model_clf4__max_depth' : range(1, 80),\n",
    "         'model_clf4__learning_rate': np.arange(0.01, 0.2, 0.01),\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "088b4097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_clf1__n_estimators': 10, 'model_clf1__max_depth': 72}\n",
      "0.29824896304709964\n",
      "{'model_clf2__solver': 'saga'}\n",
      "0.7119608149999276\n",
      "{'model_clf3__min_samples_split': 4, 'model_clf3__max_depth': 78}\n",
      "0.7229912519470202\n",
      "{'model_clf4__n_estimators': 29, 'model_clf4__max_depth': 72, 'model_clf4__learning_rate': 0.11}\n",
      "0.7249977776781972\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classificator</th>\n",
       "      <th>best_score</th>\n",
       "      <th>upsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CountVectorizer(), TfidfTransformer(), Random...</td>\n",
       "      <td>0.298249</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CountVectorizer(), TfidfTransformer(), Logist...</td>\n",
       "      <td>0.711961</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(CountVectorizer(), TfidfTransformer(), Decisi...</td>\n",
       "      <td>0.722991</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(CountVectorizer(), TfidfTransformer(), Gradie...</td>\n",
       "      <td>0.724998</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       classificator  best_score upsample\n",
       "0  (CountVectorizer(), TfidfTransformer(), Random...    0.298249       No\n",
       "1  (CountVectorizer(), TfidfTransformer(), Logist...    0.711961       No\n",
       "2  (CountVectorizer(), TfidfTransformer(), Decisi...    0.722991       No\n",
       "3  (CountVectorizer(), TfidfTransformer(), Gradie...    0.724998       No"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# обучение моделей с использованием увеличенной выборки\n",
    "models = [clf1, clf2, clf3, clf4]\n",
    "params = [param1, param2, param3, param4]\n",
    "results = pd.DataFrame({'classificator': [],\n",
    "                        'best_score': [],\n",
    "                       'upsample': []})\n",
    "\n",
    "for i in range(len(models)):\n",
    "    rs = RandomizedSearchCV(models[i], params[i], cv=3, n_jobs=-1, scoring='f1')\n",
    "    rs.fit(features_train, target_train)\n",
    "    print(rs.best_params_, rs.best_score_, sep='\\n')\n",
    "    results = results.append({'classificator': models[i],\n",
    "               'best_score': rs.best_score_,\n",
    "                'upsample': 'No'}, ignore_index=True)\n",
    "    \n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e561abc4",
   "metadata": {},
   "source": [
    "Модель показавшую наилучшее значение метрики проверим на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad1d20a",
   "metadata": {},
   "source": [
    "# Проверка на тестовой выбоке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7649d238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7385303991048116\n"
     ]
    }
   ],
   "source": [
    "pipe_lr = Pipeline([('vect', CountVectorizer()),\n",
    " ('tfidf', TfidfTransformer()),\n",
    " ('model', LogisticRegression(random_state=12345, solver = 'newton-cg'))])\n",
    "\n",
    "pipe_lr.fit(features_train, target_train)\n",
    "prediction = pipe_lr.predict(features_test)\n",
    "f1 = f1_score(target_test, prediction)\n",
    "                             \n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260eb1f",
   "metadata": {},
   "source": [
    "Посмотрим матрицу ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7761efd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m(target_test, prediction)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      3\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(target_test, prediction)\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Test Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b3e21",
   "metadata": {},
   "source": [
    "# Проверка на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5473d7fb",
   "metadata": {},
   "source": [
    "Используем простейшую модель предсказывающую один класс для проверки нашей модели на адекватность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6917d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DummyClassifier(strategy='constant', constant= 1)\n",
    "model.fit(features_train_bow, target_train)\n",
    "prediction = model.predict(features_test_bow)\n",
    "score = f1_score(target_test, prediction)\n",
    "print('f1 для простейшей модели - ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57206506",
   "metadata": {},
   "source": [
    "Для модели предсказывающей постоянное число значение метрики f1 равно 0.185. Это значительно меньше, чем у модели логистической регрессии. Следовательно выбраная нами и обученная модель адекватна."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d391bc5",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d6ecc3",
   "metadata": {},
   "source": [
    "В ходе работы наилучшей моделью для классификации комментариев на положительные и токсичные оказалась модель **LogisticRegression**. На тестовой выборке значение метрики f1 составило **0.759**. \n",
    "\n",
    "Несбалансированность классов была преодолена с помощью увеличения выборки.\n",
    "Исходные данные были подготовлены с помощью лемматизации, удаления спец символов и цифр и дальнейшей векторизации ттекста. "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2001,
    "start_time": "2022-06-20T10:16:21.393Z"
   },
   {
    "duration": 263,
    "start_time": "2022-06-20T10:16:25.737Z"
   },
   {
    "duration": 3147,
    "start_time": "2022-06-20T10:16:28.586Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-20T10:16:34.464Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-20T10:16:36.920Z"
   },
   {
    "duration": 196728,
    "start_time": "2022-06-20T10:16:43.035Z"
   },
   {
    "duration": 113,
    "start_time": "2022-06-20T10:36:29.312Z"
   },
   {
    "duration": 1466,
    "start_time": "2022-06-20T10:36:47.818Z"
   },
   {
    "duration": 203,
    "start_time": "2022-06-20T10:36:49.286Z"
   },
   {
    "duration": 614,
    "start_time": "2022-06-20T10:36:49.491Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-20T10:36:50.107Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-20T10:36:50.132Z"
   },
   {
    "duration": 183495,
    "start_time": "2022-06-20T10:36:50.141Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-20T10:39:53.637Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-20T10:39:53.645Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-20T10:39:53.676Z"
   },
   {
    "duration": 55,
    "start_time": "2022-06-20T10:39:53.694Z"
   },
   {
    "duration": 307,
    "start_time": "2022-06-20T10:39:53.750Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-20T10:39:54.059Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-20T10:40:28.840Z"
   },
   {
    "duration": 1805,
    "start_time": "2022-06-20T10:40:36.920Z"
   },
   {
    "duration": 171,
    "start_time": "2022-06-20T10:40:41.956Z"
   },
   {
    "duration": 2983,
    "start_time": "2022-06-20T10:40:46.033Z"
   },
   {
    "duration": 28,
    "start_time": "2022-06-20T10:40:52.243Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-20T10:40:54.577Z"
   },
   {
    "duration": 185142,
    "start_time": "2022-06-20T10:40:58.079Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-20T10:55:11.288Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-20T10:55:17.347Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-20T10:55:20.191Z"
   },
   {
    "duration": 75,
    "start_time": "2022-06-20T10:55:24.056Z"
   },
   {
    "duration": 255,
    "start_time": "2022-06-20T10:55:27.055Z"
   },
   {
    "duration": 8795,
    "start_time": "2022-06-20T10:56:45.821Z"
   },
   {
    "duration": 9567,
    "start_time": "2022-06-20T10:56:57.717Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-20T12:21:56.336Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-20T12:45:04.103Z"
   },
   {
    "duration": 75,
    "start_time": "2022-06-20T12:45:35.247Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-20T12:47:06.922Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-20T12:47:14.988Z"
   },
   {
    "duration": 71,
    "start_time": "2022-06-20T12:47:26.501Z"
   },
   {
    "duration": 64,
    "start_time": "2022-06-20T12:49:06.958Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-20T12:54:35.605Z"
   },
   {
    "duration": 64,
    "start_time": "2022-06-20T12:54:37.805Z"
   },
   {
    "duration": 73,
    "start_time": "2022-06-20T12:56:50.638Z"
   },
   {
    "duration": 124305,
    "start_time": "2022-06-20T12:58:56.959Z"
   },
   {
    "duration": 170349,
    "start_time": "2022-06-20T13:01:48.605Z"
   },
   {
    "duration": 73,
    "start_time": "2022-06-20T13:14:16.378Z"
   },
   {
    "duration": 119,
    "start_time": "2022-06-20T13:19:24.106Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-20T14:26:22.358Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-20T14:26:26.102Z"
   },
   {
    "duration": 46,
    "start_time": "2022-06-20T14:26:35.003Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-20T14:27:39.307Z"
   },
   {
    "duration": 48,
    "start_time": "2022-06-20T14:27:44.030Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-20T14:29:04.821Z"
   },
   {
    "duration": 45,
    "start_time": "2022-06-20T14:29:07.326Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-20T14:31:27.138Z"
   },
   {
    "duration": 2098,
    "start_time": "2022-06-20T15:44:08.933Z"
   },
   {
    "duration": 313,
    "start_time": "2022-06-20T15:44:11.033Z"
   },
   {
    "duration": 2666,
    "start_time": "2022-06-20T15:44:11.348Z"
   },
   {
    "duration": 35,
    "start_time": "2022-06-20T15:44:14.016Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-20T15:44:14.054Z"
   },
   {
    "duration": 242757,
    "start_time": "2022-06-20T15:44:14.068Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-20T15:48:16.828Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-20T15:48:16.839Z"
   },
   {
    "duration": 35,
    "start_time": "2022-06-20T15:48:16.878Z"
   },
   {
    "duration": 80,
    "start_time": "2022-06-20T15:48:16.918Z"
   },
   {
    "duration": 368,
    "start_time": "2022-06-20T15:48:17.000Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-20T15:48:17.370Z"
   },
   {
    "duration": 12352,
    "start_time": "2022-06-20T15:48:17.374Z"
   },
   {
    "duration": 13168,
    "start_time": "2022-06-20T15:48:29.729Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-20T15:48:42.900Z"
   },
   {
    "duration": 180096,
    "start_time": "2022-06-20T15:48:42.908Z"
   },
   {
    "duration": 239122,
    "start_time": "2022-06-20T15:51:43.006Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-20T15:55:42.130Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-20T15:55:42.138Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-20T15:55:42.151Z"
   },
   {
    "duration": 2092,
    "start_time": "2022-06-20T18:47:33.602Z"
   },
   {
    "duration": 331,
    "start_time": "2022-06-20T18:47:38.327Z"
   },
   {
    "duration": 2685,
    "start_time": "2022-06-20T18:47:40.533Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-20T18:47:45.851Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-20T18:47:48.257Z"
   },
   {
    "duration": 233780,
    "start_time": "2022-06-20T18:47:50.674Z"
   },
   {
    "duration": 233,
    "start_time": "2022-06-20T18:53:23.610Z"
   },
   {
    "duration": 74,
    "start_time": "2022-06-20T18:53:37.714Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.790Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.792Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.794Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.795Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.796Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.798Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.800Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.802Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.804Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.806Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.808Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.810Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.811Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.813Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.814Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.815Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.817Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.818Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.819Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.824Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.825Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.828Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.830Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-20T18:53:37.831Z"
   },
   {
    "duration": 1983,
    "start_time": "2022-06-20T18:53:47.964Z"
   },
   {
    "duration": 265,
    "start_time": "2022-06-20T18:54:03.177Z"
   },
   {
    "duration": 1189,
    "start_time": "2022-06-20T18:54:04.913Z"
   },
   {
    "duration": 44,
    "start_time": "2022-06-20T18:54:08.458Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-20T18:54:10.448Z"
   },
   {
    "duration": 417,
    "start_time": "2022-06-20T18:54:15.902Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-20T18:54:42.590Z"
   },
   {
    "duration": 2091,
    "start_time": "2022-06-20T18:54:58.031Z"
   },
   {
    "duration": 212,
    "start_time": "2022-06-20T18:55:02.249Z"
   },
   {
    "duration": 1029,
    "start_time": "2022-06-20T18:55:04.513Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-20T18:55:07.953Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-20T18:55:10.123Z"
   },
   {
    "duration": 86058,
    "start_time": "2022-06-20T18:58:29.836Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-20T19:01:38.203Z"
   },
   {
    "duration": 34,
    "start_time": "2022-06-20T19:01:41.968Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-20T19:01:44.830Z"
   },
   {
    "duration": 114,
    "start_time": "2022-06-20T19:01:47.114Z"
   },
   {
    "duration": 446,
    "start_time": "2022-06-20T19:01:49.513Z"
   },
   {
    "duration": 12474,
    "start_time": "2022-06-20T19:02:10.800Z"
   },
   {
    "duration": 12098,
    "start_time": "2022-06-20T19:05:59.139Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-20T19:06:58.459Z"
   },
   {
    "duration": 211657,
    "start_time": "2022-06-20T19:07:00.161Z"
   },
   {
    "duration": 281480,
    "start_time": "2022-06-20T19:16:22.900Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-20T19:21:04.383Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-20T19:21:04.390Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-20T19:21:22.504Z"
   },
   {
    "duration": 11241,
    "start_time": "2022-06-20T19:23:34.963Z"
   },
   {
    "duration": 251,
    "start_time": "2022-06-20T19:24:31.537Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-20T19:24:41.912Z"
   },
   {
    "duration": 39058,
    "start_time": "2022-06-20T19:26:48.077Z"
   },
   {
    "duration": 53,
    "start_time": "2022-06-20T19:29:18.236Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
